{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import contextlib\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "from typing import Any\n",
    "import requests\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph_codeact import create_codeact\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "exec_globals = builtins.__dict__.copy()\n",
    "exec_globals.update({\n",
    "    \"np\": np,\n",
    "    \"pd\": pd,\n",
    "    \"scipy\": scipy,\n",
    "    \"sklearn\": sklearn,\n",
    "    \"math\": math,\n",
    "})\n",
    "\n",
    "def eval_code(code: str, context: dict[str, Any]) -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    A safe and enhanced code evaluation function to execute generated Python code.\n",
    "    It uses traceback for detailed error reporting and handles variable scope correctly.\n",
    "    \"\"\"\n",
    "    import traceback\n",
    "\n",
    "    # The execution scope starts with the globally available libraries.\n",
    "    exec_scope = exec_globals.copy()\n",
    "    # It is then updated with the context from previous turns.\n",
    "    exec_scope.update(context)\n",
    "\n",
    "    stdout_io = io.StringIO()\n",
    "    try:\n",
    "        with contextlib.redirect_stdout(stdout_io):\n",
    "            # Execute the code in the prepared scope.\n",
    "            # New variables will be added to exec_scope.\n",
    "            exec(code, exec_scope)\n",
    "        \n",
    "        output = stdout_io.getvalue()\n",
    "        if not output:\n",
    "            output = \"<code ran, no output printed to stdout>\"\n",
    "\n",
    "    except Exception:\n",
    "        # Capture the full traceback on error.\n",
    "        output = f\"Error during execution:\\n{traceback.format_exc()}\"\n",
    "\n",
    "    # The exec_scope now contains the state after execution.\n",
    "    # We filter out any non-serializable types (like class definitions)\n",
    "    # before returning the context for the next turn.\n",
    "    context_after_exec = {\n",
    "        k: v for k, v in exec_scope.items() if not isinstance(v, type)\n",
    "    }\n",
    "    \n",
    "    return output, context_after_exec\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        openai_api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "        model=\"google/gemini-2.5-pro\",\n",
    "        streaming=False,\n",
    "        max_completion_tokens=20000,\n",
    "        request_timeout=120,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vu/miniconda3/envs/llm_adsorbate/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n",
      "Using Materials Project MACE for MACECalculator with /home/vu/.cache/mace/20231203mace128L1_epoch199model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Using head Default out of ['Default']\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vu/miniconda3/envs/llm_adsorbate/lib/python3.10/site-packages/mace/calculators/mace.py:197: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Atoms(symbols='Cu18', pbc=[True, True, False], cell=[[7.65796644025031, 0.0, 0.0], [3.828983220125155, 6.6319934785854535, 0.0], [0.0, 0.0, 12.084234471774549]], tags=..., calculator=MACECalculator(...))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.tools import read_atoms_object, relax_atoms\n",
    "\n",
    "atoms = read_atoms_object('notebooks/test_slab.xyz')\n",
    "\n",
    "relax_atoms(atoms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_adsorbate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
